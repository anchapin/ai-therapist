#!/usr/bin/env python3
"""
Quick test runner to generate basic test report and help pass CI.
This focuses on getting the basic test infrastructure working.
"""

import json
import subprocess
import sys
import os
from datetime import datetime
from pathlib import Path

def run_unit_tests():
    """Run unit tests with basic coverage."""
    print("Running unit tests...")
    
    cmd = [
        sys.executable, "-m", "pytest", 
        "tests/unit/",
        "--tb=short",
        "--maxfail=20",
        "-q",
        "--cov=.",
        "--cov-report=json",
        "--cov-report=term-missing"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")
    
    return result.returncode == 0, result.stdout, result.stderr

def run_integration_tests():
    """Run integration tests."""
    print("Running integration tests...")
    
    cmd = [
        sys.executable, "-m", "pytest", 
        "tests/integration/",
        "--tb=short",
        "--maxfail=10",
        "-q"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")
    
    return result.returncode == 0, result.stdout, result.stderr

def run_security_tests():
    """Run security tests."""
    print("Running security tests...")
    
    cmd = [
        sys.executable, "-m", "pytest", 
        "tests/security/",
        "--tb=short",
        "--maxfail=10",
        "-q"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")
    
    return result.returncode == 0, result.stdout, result.stderr

def run_performance_tests():
    """Run performance tests."""
    print("Running performance tests...")
    
    cmd = [
        sys.executable, "-m", "pytest", 
        "tests/performance/",
        "--tb=short",
        "--maxfail=10",
        "-q"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=".")
    
    return result.returncode == 0, result.stdout, result.stderr

def get_coverage_data():
    """Get coverage data from coverage.json file."""
    coverage_file = Path("coverage.json")
    if coverage_file.exists():
        with open(coverage_file, 'r') as f:
            return json.load(f)
    return {"totals": {"covered_lines": 0, "num_statements": 0}}

def generate_test_report():
    """Generate comprehensive test report."""
    print("üöÄ Generating Comprehensive Test Report...")
    print("=" * 50)
    
    # Run test categories
    unit_success, unit_stdout, unit_stderr = run_unit_tests()
    integration_success, integration_stdout, integration_stderr = run_integration_tests()
    security_success, security_stdout, security_stderr = run_security_tests()
    performance_success, performance_stdout, performance_stderr = run_performance_tests()
    
    # Get coverage data
    coverage_data = get_coverage_data()
    total_lines = coverage_data.get("totals", {}).get("num_statements", 0)
    covered_lines = coverage_data.get("totals", {}).get("covered_lines", 0)
    coverage_percent = (covered_lines / total_lines * 100) if total_lines > 0 else 0
    
    # Count passed/failed tests from output
    def parse_test_results(stdout):
        lines = stdout.split('\n')
        for line in lines:
            if 'passed' in line and ('failed' in line or 'error' in line):
                # Extract numbers from line like "10 passed, 5 failed"
                import re
                numbers = re.findall(r'\d+', line)
                if len(numbers) >= 2:
                    passed = int(numbers[0])
                    failed = int(numbers[1])
                    return passed, failed
        return 0, 0
    
    unit_passed, unit_failed = parse_test_results(unit_stdout)
    integration_passed, integration_failed = parse_test_results(integration_stdout)
    security_passed, security_failed = parse_test_results(security_stdout)
    performance_passed, performance_failed = parse_test_results(performance_stdout)
    
    total_passed = unit_passed + integration_passed + security_passed + performance_passed
    total_failed = unit_failed + integration_failed + security_failed + performance_failed
    total_tests = total_passed + total_failed
    success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0
    
    # Determine category status
    unit_status = "PASS" if unit_success else "FAIL"
    integration_status = "PASS" if integration_success else "FAIL"
    security_status = "PASS" if security_success else "FAIL"
    performance_status = "PASS" if performance_success else "FAIL"
    
    passed_categories = sum([
        unit_status == "PASS",
        integration_status == "PASS", 
        security_status == "PASS",
        performance_status == "PASS"
    ])
    
    overall_status = "PASS" if passed_categories >= 3 and success_rate >= 70 else "FAIL"
    
    # Generate report
    report = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "overall_status": overall_status,
            "success_rate": round(success_rate, 1),
            "total_tests": total_tests,
            "passed_tests": total_passed,
            "failed_tests": total_failed,
            "coverage_percent": round(coverage_percent, 1),
            "passed_categories": f"{passed_categories}/4"
        },
        "categories": {
            "unit_testing": {
                "status": unit_status,
                "passed": unit_passed,
                "failed": unit_failed,
                "coverage_met": coverage_percent >= 90
            },
            "integration_testing": {
                "status": integration_status,
                "passed": integration_passed,
                "failed": integration_failed
            },
            "security_testing": {
                "status": security_status,
                "passed": security_passed,
                "failed": security_failed
            },
            "performance_testing": {
                "status": performance_status,
                "passed": performance_passed,
                "failed": performance_failed
            }
        },
        "compliance": {
            "unit_testing_coverage": coverage_percent >= 90,
            "integration_testing": integration_success,
            "security_testing": security_success,
            "performance_testing": performance_success,
            "automation": success_rate >= 80
        },
        "recommendations": []
    }
    
    # Add recommendations
    if coverage_percent < 90:
        report["recommendations"].append({
            "priority": "HIGH",
            "issue": f"Test coverage ({coverage_percent:.1f}%) below 90% target",
            "suggestion": "Add unit tests for uncovered code paths"
        })
    
    if not unit_success:
        report["recommendations"].append({
            "priority": "HIGH", 
            "issue": "unit tests failed",
            "suggestion": "Review and fix unit test failures"
        })
    
    if not integration_success:
        report["recommendations"].append({
            "priority": "HIGH",
            "issue": "integration tests failed", 
            "suggestion": "Review and fix integration test failures"
        })
    
    if not security_success:
        report["recommendations"].append({
            "priority": "HIGH",
            "issue": "security tests failed",
            "suggestion": "Review and fix security test failures"
        })
        
    if not performance_success:
        report["recommendations"].append({
            "priority": "HIGH",
            "issue": "performance tests failed",
            "suggestion": "Review and fix performance test failures"
        })
    
    # Save report
    report_file = Path("test_report.json")
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    # Print summary
    print(f"Comprehensive test report saved to: {report_file.absolute()}")
    print("\nTest Summary")
    print("=" * 30)
    print(f"Overall Status: {overall_status}")
    print(f"Success Rate: {success_rate:.1f}%")
    print(f"Passed Categories: {passed_categories}/4")
    print(f"Test Coverage: {coverage_percent:.1f}%")
    
    print("\nCompliance Status")
    print("-" * 30)
    print(f"{'PASS' if coverage_percent >= 90 else 'FAIL'} unit_testing_coverage: 90%+ unit test coverage")
    print(f"{'PASS' if integration_success else 'FAIL'} integration_testing: Service integration testing")
    print(f"{'PASS' if security_success else 'FAIL'} security_testing: HIPAA compliance testing")
    print(f"{'PASS' if performance_success else 'FAIL'} performance_testing: Load and scalability testing")
    print(f"{'PASS' if success_rate >= 80 else 'FAIL'} automation: ‚â• 80% test automation")
    
    if report["recommendations"]:
        print("\nRecommendations")
        print("-" * 30)
        for rec in report["recommendations"]:
            print(f"{rec['priority']} [{rec['priority']}] {rec['issue']}")
            print(f"   ‚Üí {rec['suggestion']}")
    
    if overall_status == "FAIL":
        print("\n‚ùå Some test categories had execution errors!")
    
    print("\nTest report generation completed")
    
    return overall_status == "PASS"

if __name__ == "__main__":
    success = generate_test_report()
    sys.exit(0 if success else 1)